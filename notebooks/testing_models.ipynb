{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEmbedder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels, channels, embedding_size,\n",
    "                 kernal_size=7, use_bias=False):\n",
    "        super().__init__()\n",
    "        self.separable_conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, channels,\n",
    "                      kernel_size=(kernal_size, 1), padding=1,\n",
    "                      bias=use_bias),\n",
    "            nn.Conv2d(channels, channels,\n",
    "                      kernel_size=(1, kernal_size), padding=2,\n",
    "                      bias=use_bias),\n",
    "        )\n",
    "        self.linear = nn.Linear(channels * 32 * 32, embedding_size,\n",
    "                                bias=use_bias)\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        hidden = F.relu(self.separable_conv(image))\n",
    "        return self.linear(torch.flatten(hidden, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_embedder = SimpleEmbedder(3, 32, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_embedder(torch.randn(1, 3, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNRouter(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, operations, use_input_embedding=True,\n",
    "                 weight_tie_output_layer=True, use_bias=True) -> None:\n",
    "        '''\n",
    "        Args:\n",
    "            hidden_size:\n",
    "            operations:\n",
    "            use_input_embedding:\n",
    "            weight_tie_output_layer:\n",
    "            bias:\n",
    "        Returns:\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_input_embedding = use_input_embedding\n",
    "        self.operation_embedding = nn.Parameter(\n",
    "            torch.empty(operations, hidden_size).uniform_(-0.1, 0.1)\n",
    "        )\n",
    "        if use_input_embedding:\n",
    "            self.input_embedding = torch.empty(1, hidden_size).uniform_(-0.1, 0.1)\n",
    "        self.rnn_cell = nn.GRUCell(hidden_size, hidden_size,\n",
    "                                   bias=use_bias)\n",
    "        self.output_layer = nn.Linear(hidden_size, operations,\n",
    "                                bias=use_bias)\n",
    "    \n",
    "    def forward(self, hidden_state, last_decision=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        batch_size = hidden_state.size(0)\n",
    "        if last_decision is None:\n",
    "            if self.use_input_embedding:\n",
    "                input_state = self.input_embedding.expand(batch_size, -1)\n",
    "            else:\n",
    "                input_state = torch.zeros(batch_size, self.hidden_size).uniform_(-0.1, 0.1)\n",
    "        else:\n",
    "            input_state = last_decision @ self.operations_embeddings\n",
    "        hidden = self.rnn_cell(input_state, hidden_state)\n",
    "        return hidden, self.output_layer(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_router = RNNRouter(128, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_router(torch.randn(1, 128))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(routing_function: Callable, beams, temperature: float = 1.):\n",
    "    batch_size =\n",
    "    batches_operations_reshape = (-1, beams)\n",
    "    batches_beams_operations_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearch:\n",
    "    \n",
    "    def __init__(self, beams: int,\n",
    "                 operations: int, maximum_depth: int,\n",
    "                 preserve_zeros_grad: bool = True):\n",
    "        self.rout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
